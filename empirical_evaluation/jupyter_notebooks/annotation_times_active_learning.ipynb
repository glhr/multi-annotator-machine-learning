{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# $\\texttt{dopanim}$: Annotation Times in Active Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pylab as plt\n",
    "import sys\n",
    "\n",
    "# TODO: Append the path to your `multi-annotator-machine-learning` project.\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from maml.data import Dopanim\n",
    "from maml.data import SSLDatasetWrapper\n",
    "from skactiveml.pool import UncertaintySampling, RandomSampling\n",
    "from skactiveml.utils import MISSING_LABEL\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# TODO: Adjust data path to your dataset.\n",
    "DATA_PATH = \".\"\n",
    "\n",
    "# TODO: Adjust flag for downloading the dataset.\n",
    "DOWNLOAD = False\n",
    "\n",
    "# TODO: Adjust path for saving figures.\n",
    "FIGURE_PATH = \".\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Training and Test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DinoV2 model as SSL backbone.\n",
    "repo_or_dir = \"facebookresearch/dinov2\"\n",
    "model = \"dinov2_vits14\"\n",
    "ssl_model = torch.hub.load(repo_or_dir=repo_or_dir, model=model)\n",
    "\n",
    "# Load training and test dataset, including annotation times as averages per sample\n",
    "test_ds = Dopanim(DATA_PATH, version='test', variant='full', download=DOWNLOAD)\n",
    "train_ds = Dopanim(DATA_PATH, version='train', variant='full', transform=test_ds.transform, download=DOWNLOAD)\n",
    "train_times = train_ds.load_annotation_times(train_ds.observation_ids, train_ds.annotators)\n",
    "train_times[train_times == -1] = np.nan\n",
    "train_times = np.nanmean(train_times, axis=-1)\n",
    "\n",
    "# Enable usage of cached datasets.\n",
    "train_ds = SSLDatasetWrapper(dataset=train_ds, model=ssl_model, cache=True)\n",
    "test_ds = SSLDatasetWrapper(dataset=test_ds, model=ssl_model, cache=True)\n",
    "\n",
    "# Create numpy arrays of training and test datasets for usage with `scikit-activeml`.\n",
    "X_train, y_train = [], []\n",
    "for data in train_ds:\n",
    "    X_train.append(data['x'].numpy())\n",
    "    y_train.append(data['y'].numpy())\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test, y_test = [], []\n",
    "for data in test_ds:\n",
    "    X_test.append(data['x'].numpy())\n",
    "    y_test.append(data['y'].numpy())\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Helper Functions for Active Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def al_cycle(al_strat: str=\"random\", num_init: int=10, num_acq: int=19, batch_size: int=10, seed: int=42):\n",
    "    \"\"\"\n",
    "    Helper function for performing an active learning cycle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    al_strat : 'random'' or 'margin'\n",
    "        Name of the active learning strategy.\n",
    "    num_init : int\n",
    "        Number of initially labelled samples.\n",
    "    num_acq : int\n",
    "        Number of label acquisition cycles.\n",
    "    batch_size : int\n",
    "        Number of label acquisitions per cycle.\n",
    "    seed : int\n",
    "        Seed to ensure reproducibility.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    learning_curve: list\n",
    "        Learning curve as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    y_pool = np.full(shape=y_train.shape, fill_value=MISSING_LABEL)\n",
    "\n",
    "    init_indices = np.random.choice(range(len(X_train)), size=num_init, replace=False)\n",
    "    y_pool[init_indices] = y_train[init_indices]\n",
    "\n",
    "    if al_strat == 'random':\n",
    "        qs = RandomSampling(random_state=seed)\n",
    "    elif al_strat == 'margin':\n",
    "        qs = UncertaintySampling(random_state=seed, method='margin_sampling')\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    learning_curve = []\n",
    "    query_idx = None\n",
    "    for i_acq in tqdm(range(num_acq + 1)):\n",
    "        if i_acq != 0:\n",
    "            if al_strat == 'random':\n",
    "                query_idx = qs.query(X=X_train, y=y_pool, batch_size=batch_size)\n",
    "            elif al_strat == 'margin':\n",
    "                query_idx = qs.query(X=X_train, y=y_pool, clf=clf, batch_size=batch_size)\n",
    "            else: \n",
    "                raise NotImplementedError()\n",
    "            y_pool[query_idx] = y_train[query_idx]\n",
    "\n",
    "        clf = SklearnClassifier(\n",
    "            LogisticRegression(random_state=seed, max_iter=3000),\n",
    "            classes=np.unique(y_train),\n",
    "            random_state=seed,\n",
    "        )\n",
    "        clf.fit(X_train, y_pool)\n",
    "\n",
    "        query_indices = np.where(~np.isnan(y_pool))[0].tolist()\n",
    "        anno_time = np.mean(train_times[query_idx]) if query_idx is not None else np.mean(train_times[query_indices])\n",
    "        result = {\n",
    "            # 'query_indices': query_indices,\n",
    "            'num_samples': len(query_indices),\n",
    "            'anno_time': anno_time,\n",
    "            'test_acc': clf.score(X_test, y_test),\n",
    "        }\n",
    "        learning_curve.append(result)\n",
    "    return learning_curve\n",
    "\n",
    "def avg_lcs(learning_curve: list):\n",
    "    \"\"\"\n",
    "    Computes averages and standard deviations of the learning curves.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_curve : list\n",
    "        Learning curve as a list of dictionaries.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    avg_lc : list\n",
    "        Averages of the given learning curves.\n",
    "    std_lc : list\n",
    "        Standard deviations of the given learning curves.\n",
    "    \"\"\"\n",
    "    avg_lc = [{k: [] for k in d} for d in learning_curve[0]]\n",
    "    for lc in learning_curve:\n",
    "        for cycle_dict, avg_cycle_dict in zip(lc, avg_lc):\n",
    "            for key in cycle_dict:\n",
    "                avg_cycle_dict[key].append(cycle_dict[key])\n",
    "    avg_lc_std = [{key: np.std(val) for key, val in d.items()} for d in avg_lc]\n",
    "    avg_lc = [{key: np.mean(val) for key, val in d.items()} for d in avg_lc]\n",
    "    return avg_lc, avg_lc_std"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform Active Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define active learning setup.\n",
    "num_init = 100\n",
    "batch_size = 100\n",
    "num_acq = 19\n",
    "\n",
    "# Perform active learning.\n",
    "lcs_random = []\n",
    "lcs_margin = []\n",
    "for seed in range(50):\n",
    "    print(seed)\n",
    "    lcs_random.append(al_cycle('random', num_init=num_init, num_acq=num_acq, batch_size=batch_size, seed=seed))\n",
    "    lcs_margin.append(al_cycle('margin', num_init=num_init, num_acq=num_acq, batch_size=batch_size, seed=seed))\n",
    "    \n",
    "# Evaluate learning curves.\n",
    "avg_lc_random, avg_lc_random_std = avg_lcs(lcs_random)\n",
    "avg_lc_margin, avg_lc_margin_std = avg_lcs(lcs_margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Active Learning Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot([d['num_samples'] for d in avg_lc_random], [d['test_acc'] for d in avg_lc_random], label='Random', color=\"#e580ffff\")\n",
    "plt.fill_between([d['num_samples'] for d in avg_lc_random], np.subtract([d['test_acc'] for d in avg_lc_random], [d['test_acc'] for d in avg_lc_random_std]), np.add([d['test_acc'] for d in avg_lc_random], [d['test_acc'] for d in avg_lc_random_std]), alpha=.3, color=\"#e580ffff\")\n",
    "plt.plot([d['num_samples'] for d in avg_lc_margin], [d['test_acc'] for d in avg_lc_margin], label='Margin', color=\"#5fd3bcff\")\n",
    "plt.fill_between([d['num_samples'] for d in avg_lc_margin], np.subtract([d['test_acc'] for d in avg_lc_margin], [d['test_acc'] for d in avg_lc_margin_std]), np.add([d['test_acc'] for d in avg_lc_margin], [d['test_acc'] for d in avg_lc_margin_std]), alpha=.3, color=\"#5fd3bcff\")\n",
    "plt.xticks(np.arange(0, 2250, step=500))\n",
    "plt.yticks(np.arange(0.55, 0.95, step=0.1))\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot([d['num_samples'] for d in avg_lc_random], [d['anno_time'] for d in avg_lc_random], label='Random', color=\"#e580ffff\")\n",
    "plt.fill_between(\n",
    "    [d['num_samples'] for d in avg_lc_random], \n",
    "    np.subtract([d['anno_time'] for d in avg_lc_random], [d['anno_time'] for d in avg_lc_random_std]), \n",
    "    np.add([d['anno_time'] for d in avg_lc_random], [d['anno_time'] for d in avg_lc_random_std]), \n",
    "    alpha=.3, color=\"#e580ffff\")\n",
    "plt.plot([d['num_samples'] for d in avg_lc_margin], [d['anno_time'] for d in avg_lc_margin], label='Margin', color=\"#5fd3bcff\")\n",
    "plt.fill_between(\n",
    "    [d['num_samples'] for d in avg_lc_margin], \n",
    "    np.subtract([d['anno_time'] for d in avg_lc_margin], [d['anno_time'] for d in avg_lc_margin_std]), \n",
    "    np.add([d['anno_time'] for d in avg_lc_margin], [d['anno_time'] for d in avg_lc_margin_std]), \n",
    "    alpha=.3, color=\"#5fd3bcff\")\n",
    "plt.xticks(np.arange(0, 2250, step=500))\n",
    "plt.yticks([7, 7.5, 8.0])\n",
    "plt.savefig(os.path.join(FIGURE_PATH, \"annotation_times_active_learning.pdf\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crowd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
